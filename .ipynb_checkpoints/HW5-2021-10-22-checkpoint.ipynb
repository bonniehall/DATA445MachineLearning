{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60fb8ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "## HW 5 DATA 445 Due 2021.10.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c927c107",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q1 If a decision tree is under-fitting the training dataset, is it a good idea to try scaling\n",
    "## the input features?\n",
    "\n",
    "## Scaling the data is not required for tree-based models (although it is required to compare the tree\n",
    "## to any non-tree based model). Scaling the data will not improve the fit. Instead other hyper-\n",
    "## parameters should be tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aacbcf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q2 If a decision tree is over-fitting the training dataset, is it a good idea to try decreasing\n",
    "## max_depth?\n",
    "\n",
    "## Yes, over-fitting of a decision tree can be caused by too many layers (depth) in the model.\n",
    "## Reducing the max_depth limits the amount of fitting performed with the data and can reduce\n",
    "## overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e2faeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q3 Why would you use a random forest instead of a decision tree?\n",
    "##      (a) For a lower training error.\n",
    "##      (b) To reduce the variance of the model.\n",
    "##      (c) For a model that it is easier for human to interpret.\n",
    "\n",
    "## (b) to reduce the variance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b48fd898",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q4 Which of the following is/are TRUE about bagging trees?\n",
    "##      (a) In bagging trees, the trees are grown independent of each other.\n",
    "##      (b) In bagging trees, the trees are grown in sequence.\n",
    "##      (c) Bagging is a method for improving the performance by aggregating the results of weak learners.\n",
    "\n",
    "## (d)  A and C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff704d8e",
   "metadata": {},
   "source": [
    "Q5 Suppose you are building random forest model, which split a node on the attribute, that has highest information gain (using the Gini index). In the below image, which attribute which has the highest information gain? Show all your calculations.\n",
    "\n",
    "outlook:  \n",
    "\n",
    "        sunny 2 yes, 3 no  ---> Gini index = 1- (2/5)^2- (3/5)^2 = 0.48\n",
    "\n",
    "        overcast 4 yes, 0 no ---> Gini index = 1 - (4/4)^2 - (0/4)^2 = 0\n",
    "          \n",
    "        rainy 3 yes, 2 no ---> Gini index = 1 - (3/5)^2 - (2/5)^2 = 0.48\n",
    "        \n",
    "        Average = 0.32\n",
    "          \n",
    "temperature:   \n",
    "\n",
    "          hot 2 yes, 2 no ---> Gini index = 1- (2/4)^2- (2/4)^2 = 0.5\n",
    "\n",
    "          mild 4 yes, 2 no ---> Gini index = 1- (4/6)^2- (2/6)^2 = 0.44\n",
    "\n",
    "          cool 3 yes, 1 no ---> Gini index = 1- (3/4)^2- (1/4)^2 = 0.38\n",
    "          \n",
    "          Average = 0.44\n",
    "\n",
    "windy: \n",
    "\n",
    "        false 6 yes, 2 no ---> Gini index = 1- (6/8)^2- (2/8)^2 = 0.38\n",
    "\n",
    "        true 3 yes, 3 no ---> Gini index = 1- (3/6)^2- (3/6)^2 = 0.5\n",
    "        \n",
    "        Average = 0.44\n",
    "\n",
    "       \n",
    "humidity: \n",
    "\n",
    "        high 3 yes, 4 no ---> Gini index = 1- (3/7)^2- (4/7)^2 = 0.49\n",
    "\n",
    "        normal 6 yes, 1 no ---> Gini index = 1- (6/7)^2- (1/7)^2 = 0.24\n",
    "        \n",
    "        Average = 0.37\n",
    "\n",
    "The lowest average Gini impurity index is for \"outlook\", and so this is the variable that provides the most information gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef1cf7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male  age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0     1   39        4.0              0         0.0     0.0                0   \n",
       "1     0   46        2.0              0         0.0     0.0                0   \n",
       "2     1   48        1.0              1        20.0     0.0                0   \n",
       "3     0   61        3.0              1        30.0     0.0                0   \n",
       "4     0   46        3.0              1        23.0     0.0                0   \n",
       "\n",
       "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
       "0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
       "1             0         0    250.0  121.0   81.0  28.73       95.0     76.0   \n",
       "2             0         0    245.0  127.5   80.0  25.34       75.0     70.0   \n",
       "3             1         0    225.0  150.0   95.0  28.58       65.0    103.0   \n",
       "4             0         0    285.0  130.0   84.0  23.10       85.0     85.0   \n",
       "\n",
       "   TenYearCHD  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q6a Load the data file to your S3 bucket. Using the pandas library, read the csv data\n",
    "## file and create a data-frame called heart.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Defining the s3 bucket\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'bonnieh-data-445-bucket'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "## Defining the file to be used\n",
    "file_key = 'framingham.csv'\n",
    "\n",
    "bucket_object = bucket.Object(file_key)\n",
    "file_object = bucket_object.get()\n",
    "file_content_stream = file_object.get('Body')\n",
    "\n",
    "## Reading the csv file\n",
    "heart = pd.read_csv(file_content_stream)\n",
    "heart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19b53732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['male',\n",
       " 'age',\n",
       " 'education',\n",
       " 'currentSmoker',\n",
       " 'cigsPerDay',\n",
       " 'BPMeds',\n",
       " 'prevalentStroke',\n",
       " 'prevalentHyp',\n",
       " 'diabetes',\n",
       " 'totChol',\n",
       " 'sysBP',\n",
       " 'diaBP',\n",
       " 'BMI',\n",
       " 'heartRate',\n",
       " 'glucose',\n",
       " 'TenYearCHD']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q6b  Remove observations with missing values.\n",
    "\n",
    "heart = heart.dropna()\n",
    "heart.head()\n",
    "list(heart.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5cedce",
   "metadata": {},
   "source": [
    "Q6c Using all the available variables as the predictor variables, and TenYearCHD asthe target variable, do the following:\n",
    "\n",
    "   (i) Split the data into train (80%) and test (20%) (taking into account the proportion of 0s and 1s).\n",
    "   \n",
    "   (ii) Using the train data-frame, build a random forest classifier (using 500 trees).\n",
    "   \n",
    "  (iii) Extra the feature importance of each of the variables.\n",
    "\n",
    "\n",
    "Repeat (i)-(iii) 100 times. Compute the average importance of each of the variables across the 100 splits. After that, select the top 5 variables (the ones with top 5 average importance) as the predictor variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d727b21a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021121</td>\n",
       "      <td>0.128546</td>\n",
       "      <td>0.036519</td>\n",
       "      <td>0.012632</td>\n",
       "      <td>0.051002</td>\n",
       "      <td>0.006713</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>0.016627</td>\n",
       "      <td>0.006433</td>\n",
       "      <td>0.119315</td>\n",
       "      <td>0.132603</td>\n",
       "      <td>0.119737</td>\n",
       "      <td>0.127447</td>\n",
       "      <td>0.094588</td>\n",
       "      <td>0.123093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.022080</td>\n",
       "      <td>0.126829</td>\n",
       "      <td>0.035689</td>\n",
       "      <td>0.013267</td>\n",
       "      <td>0.050248</td>\n",
       "      <td>0.007893</td>\n",
       "      <td>0.003187</td>\n",
       "      <td>0.018595</td>\n",
       "      <td>0.006612</td>\n",
       "      <td>0.118319</td>\n",
       "      <td>0.135159</td>\n",
       "      <td>0.118687</td>\n",
       "      <td>0.129181</td>\n",
       "      <td>0.096434</td>\n",
       "      <td>0.117821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.022272</td>\n",
       "      <td>0.125643</td>\n",
       "      <td>0.035588</td>\n",
       "      <td>0.012857</td>\n",
       "      <td>0.051125</td>\n",
       "      <td>0.007119</td>\n",
       "      <td>0.002478</td>\n",
       "      <td>0.018079</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>0.124099</td>\n",
       "      <td>0.131941</td>\n",
       "      <td>0.116488</td>\n",
       "      <td>0.127724</td>\n",
       "      <td>0.099474</td>\n",
       "      <td>0.118726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.020201</td>\n",
       "      <td>0.124898</td>\n",
       "      <td>0.035505</td>\n",
       "      <td>0.011922</td>\n",
       "      <td>0.051703</td>\n",
       "      <td>0.005371</td>\n",
       "      <td>0.002456</td>\n",
       "      <td>0.019433</td>\n",
       "      <td>0.006255</td>\n",
       "      <td>0.119035</td>\n",
       "      <td>0.137200</td>\n",
       "      <td>0.118153</td>\n",
       "      <td>0.129819</td>\n",
       "      <td>0.096361</td>\n",
       "      <td>0.121686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.023556</td>\n",
       "      <td>0.126859</td>\n",
       "      <td>0.036460</td>\n",
       "      <td>0.012607</td>\n",
       "      <td>0.051452</td>\n",
       "      <td>0.006121</td>\n",
       "      <td>0.002889</td>\n",
       "      <td>0.018778</td>\n",
       "      <td>0.006390</td>\n",
       "      <td>0.123480</td>\n",
       "      <td>0.133192</td>\n",
       "      <td>0.121380</td>\n",
       "      <td>0.126732</td>\n",
       "      <td>0.096079</td>\n",
       "      <td>0.114027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       male       age  education  currentSmoker  cigsPerDay    BPMeds  \\\n",
       "0  0.021121  0.128546   0.036519       0.012632    0.051002  0.006713   \n",
       "1  0.022080  0.126829   0.035689       0.013267    0.050248  0.007893   \n",
       "2  0.022272  0.125643   0.035588       0.012857    0.051125  0.007119   \n",
       "3  0.020201  0.124898   0.035505       0.011922    0.051703  0.005371   \n",
       "4  0.023556  0.126859   0.036460       0.012607    0.051452  0.006121   \n",
       "\n",
       "   prevalentStroke  prevalentHyp  diabetes   totChol     sysBP     diaBP  \\\n",
       "0         0.003623      0.016627  0.006433  0.119315  0.132603  0.119737   \n",
       "1         0.003187      0.018595  0.006612  0.118319  0.135159  0.118687   \n",
       "2         0.002478      0.018079  0.006386  0.124099  0.131941  0.116488   \n",
       "3         0.002456      0.019433  0.006255  0.119035  0.137200  0.118153   \n",
       "4         0.002889      0.018778  0.006390  0.123480  0.133192  0.121380   \n",
       "\n",
       "        BMI  heartRate   glucose  \n",
       "0  0.127447   0.094588  0.123093  \n",
       "1  0.129181   0.096434  0.117821  \n",
       "2  0.127724   0.099474  0.118726  \n",
       "3  0.129819   0.096361  0.121686  \n",
       "4  0.126732   0.096079  0.114027  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## defining the variables\n",
    "\n",
    "X = heart[['male','age','education','currentSmoker','cigsPerDay','BPMeds','prevalentStroke','prevalentHyp',\n",
    "'diabetes','totChol','sysBP','diaBP','BMI','heartRate','glucose']]\n",
    "Y = heart['TenYearCHD']\n",
    "\n",
    "## defining a list to capture the feature importances\n",
    "\n",
    "var_imprt = []\n",
    "\n",
    "for i in range(0, 100):\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify = Y)\n",
    "\n",
    "    RF_var = RandomForestClassifier(n_estimators = 500).fit(X_train, Y_train)\n",
    "    var_imprt.append(RF_var.feature_importances_)\n",
    "    \n",
    "var_imprt_df= pd.DataFrame(var_imprt, columns = ['male','age','education','currentSmoker','cigsPerDay','BPMeds','prevalentStroke','prevalentHyp',\n",
    "'diabetes','totChol','sysBP','diaBP','BMI','heartRate','glucose'])\n",
    "var_imprt_df.head()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23a7bbb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prevalentStroke    0.003233\n",
       "diabetes           0.006472\n",
       "BPMeds             0.007032\n",
       "currentSmoker      0.012539\n",
       "prevalentHyp       0.018249\n",
       "male               0.021238\n",
       "education          0.036829\n",
       "cigsPerDay         0.050419\n",
       "heartRate          0.095871\n",
       "diaBP              0.118966\n",
       "glucose            0.119874\n",
       "totChol            0.121648\n",
       "age                0.125191\n",
       "BMI                0.127014\n",
       "sysBP              0.135425\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_imprt_df.mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2af2e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "## the 5 variables with the highest feature_importances scores are \n",
    "## sysBP, BMI, age, totChol and glucose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53f6ed5",
   "metadata": {},
   "source": [
    "Q6d. Using the top 5 variables from part (c) as the predictor variables and TenYearCHD as the target variable, do the following:\n",
    "\n",
    "(i) Split the data into train (80%) and test (20%) (taking into account the proportion of\n",
    "0s and 1s).\n",
    "\n",
    "(ii) Using the train data-frame, build a random forest classifier (using 500 trees and maximum depth tree equal to 3). Using this model, predict the likelihood of risk of coronary disease of the patients in the test data-frame. Using 10% as cutoff value, report the recall.\n",
    "\n",
    "(iii) Using the train data-frame, build a random forest classifier (using 500 trees and maximum depth tree equal to 5). Using this model, predict the likelihood of risk of coronary disease of the patients in the test data-frame. Using 10% as cutoff value, report the recall.\n",
    "\n",
    "(iv) Using the train data-frame, build a random forest classifier (using 500 trees and maximum depth tree equal to 7). Using this model, predict the likelihood of risk of coronary disease of the patients in the test data-frame. Using 10% as cutoff value, report the recall.\n",
    "\n",
    "Repeat (i)-(iii) 100 times. Compute the average recall of each of the models across the 100 iterations. What model would use to predict TenYearCHD? Be specific."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36e54525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average recall for the RF1 model (max_depth=3) is 0.8362 . The average recall for the RF2 model (max_depth=5) is 0.8238 . The average recall for the RF3 model (max_depth=7) is 0.8362 .\n"
     ]
    }
   ],
   "source": [
    "## defining the selected variable set\n",
    "X2 = heart[['sysBP', 'BMI', 'age', 'totChol','glucose']]\n",
    "Y2 = heart['TenYearCHD']\n",
    "\n",
    "## defining lists to collect the recall values\n",
    "\n",
    "recalls_RF1 = []\n",
    "recalls_RF2 = []\n",
    "recalls_RF3 = []\n",
    "\n",
    "for i in range (0, 100):\n",
    "    ## splitting the data\n",
    "    X2_train, X2_test, Y2_train, Y2_test = train_test_split(X2, Y2, test_size = 0.2, stratify = Y2)\n",
    "\n",
    "    ## RF model 1, max_depth = 3\n",
    "    RF1 = RandomForestClassifier(n_estimators = 500, max_depth = 3).fit(X2_train, Y2_train)\n",
    "    RF1_pred = RF1.predict_proba(X2_test)[:,1]\n",
    "    RF1_pred = np.where(RF1_pred < 0.1, 0, 1)\n",
    "    recalls_RF1.append(recall_score(Y2_test, RF1_pred))\n",
    "\n",
    "    ## RF model 2, max_depth = 5\n",
    "    RF2 = RandomForestClassifier(n_estimators = 500, max_depth = 5).fit(X2_train, Y2_train)\n",
    "    RF2_pred = RF2.predict_proba(X2_test)[:,1]\n",
    "    RF2_pred = np.where(RF2_pred < 0.1, 0, 1)\n",
    "    recalls_RF2.append(recall_score(Y2_test, RF2_pred))\n",
    "\n",
    "    ## RF model 3, max_depth = 7\n",
    "    RF3 = RandomForestClassifier(n_estimators = 500, max_depth = 7).fit(X2_train, Y2_train)\n",
    "    RF3_pred = RF3.predict_proba(X2_test)[:,1]\n",
    "    RF3_pred = np.where(RF3_pred < 0.1, 0, 1)\n",
    "    recalls_RF3.append(recall_score(Y2_test, RF3_pred))\n",
    "\n",
    "avg_recall_RF1 = np.mean(recalls_RF1)\n",
    "avg_recall_RF2 = np.mean(recalls_RF2)\n",
    "avg_recall_RF3 = np.mean(recalls_RF1)\n",
    "\n",
    "print('The average recall for the RF1 model (max_depth=3) is', round(avg_recall_RF1, 4),\n",
    "      '. The average recall for the RF2 model (max_depth=5) is', round(avg_recall_RF2,4),\n",
    "     '. The average recall for the RF3 model (max_depth=7) is', round(avg_recall_RF3, 4),'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea1418ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Based on the average recall scores, I would pick the random forest model with 500 trees and a max_depth\n",
    "## of 3. This model has the highest recall score, with the same value as the model with a max_depth of 7.\n",
    "## But a simpler model with the same recall value is a better choice--so a max_depth of 3 is preferred."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
